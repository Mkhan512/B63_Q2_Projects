{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT/a5dCvJYBLYj+GBr0b0a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mkhan512/B63_Q2_Projects/blob/main/Caht_Bote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r4bCINbBsN_m"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\" # Install the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n"
      ],
      "metadata": {
        "id": "Y0rJYTG1scmO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=\"AIzaSyA1pDOzxirKzxO0Id6W5Y9WCSA9V7IpLgY\")"
      ],
      "metadata": {
        "id": "tWpUJExevyG0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "response = model_1.generate_content(input(\"type any thing:\")) #\"Explain how chatbot works\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "collapsed": true,
        "id": "jSN0fRxHsybb",
        "outputId": "c0f00580-4f31-4b7a-b0cc-152c2d744a69"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type any thing:What is LLM? 5 key points\n",
            "LLM stands for Large Language Model. Here are 5 key points:\n",
            "\n",
            "1. **Massive Datasets:** LLMs are trained on enormous datasets of text and code, allowing them to learn patterns, relationships, and nuances of human language.  The scale of these datasets is a defining characteristic.\n",
            "\n",
            "2. **Predictive Text Generation:**  Their primary function is to predict the next word (or token) in a sequence.  This predictive ability allows them to generate human-like text, translate languages, and answer questions in a conversational manner.\n",
            "\n",
            "3. **Deep Learning Architecture:** LLMs are built using deep learning architectures, typically transformer networks, which excel at processing sequential data like text.  These networks have multiple layers that learn increasingly complex representations of language.\n",
            "\n",
            "4. **Transfer Learning:**  The knowledge acquired during training on massive datasets can be transferred to various downstream tasks with relatively little additional training data. This makes them adaptable and versatile.\n",
            "\n",
            "5. **Limitations & Biases:**  Despite their capabilities, LLMs have limitations. They can sometimes generate inaccurate, nonsensical, or biased outputs reflecting biases present in their training data.  Ethical considerations and responsible deployment are crucial.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K11ikEaiwNbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}