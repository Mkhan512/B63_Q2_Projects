{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq4eoky/PfLA8jVk7C6n76",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mkhan512/B63_Q2_Projects/blob/LangChain_Projects/1st_LangChainProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project 1: LangChain Hello World Project\n",
        "            In this Project, we will create a simple LangChain Colab Notebook that uses the Google Gemini Flash 2.0 model to answer user questions. This example below is provided to help you get started assumes you have access to the Gemini API and a basic Python environment. However, you are required to develop and submit your project using Google Colab."
      ],
      "metadata": {
        "id": "kjDcrBbn81yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Set Up the Environment"
      ],
      "metadata": {
        "id": "u3zPBCPiwb2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y build-essential libtool autoconf python3-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xDRxvNzoqP7A",
        "outputId": "d23d4d01-c226-405e-9e51-3453b94d9edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 3,626 B/3,626 B 100%] [Conn\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,564 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,517 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,630 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,448 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,614 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,830 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Fetched 26.9 MB in 3s (8,872 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "autoconf is already the newest version (2.71-2).\n",
            "autoconf set to manually installed.\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "python3-dev set to manually installed.\n",
            "Suggested packages:\n",
            "  libtool-doc gcj-jdk\n",
            "The following NEW packages will be installed:\n",
            "  libtool\n",
            "0 upgraded, 1 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 164 kB of archives.\n",
            "After this operation, 1,227 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtool all 2.4.6-15build2 [164 kB]\n",
            "Fetched 164 kB in 1s (229 kB/s)\n",
            "Selecting previously unselected package libtool.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../libtool_2.4.6-15build2_all.deb ...\n",
            "Unpacking libtool (2.4.6-15build2) ...\n",
            "Setting up libtool (2.4.6-15build2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://libarchive.googlecode.com/files/libarchive-3.0.3.tar.gz\n",
        "!tar xzf libarchive-3.0.3.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yftjo6RfpKW9",
        "outputId": "4441ce01-dbe0-43cf-8b0d-49bc00bf3459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-22 18:38:32--  http://libarchive.googlecode.com/files/libarchive-3.0.3.tar.gz\n",
            "Resolving libarchive.googlecode.com (libarchive.googlecode.com)... 142.250.141.82, 2607:f8b0:4023:c0b::52\n",
            "Connecting to libarchive.googlecode.com (libarchive.googlecode.com)|142.250.141.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-12-22 18:38:33 ERROR 404: Not Found.\n",
            "\n",
            "tar (child): libarchive-3.0.3.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd libarchive-3.0.3\n",
        "!./build/autogen.sh\n",
        "!./configure --prefix=/usr/local\n",
        "!make\n",
        "!make install"
      ],
      "metadata": {
        "id": "2eVbrU-Oo0EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tT7FRAlVpt0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain.GOOGLE_genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HXGEk7KQpAmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "epXuin4Hwryh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gkmXEjAMxVh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install google-generative-ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQj3tTAzw66T",
        "outputId": "ff66bd0d-379d-4a27-eff7-a2f06a7d5ea5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package google-generative-ai\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Configure the Gemini Flash Model"
      ],
      "metadata": {
        "id": "M9ZEUwwVwpry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "Gemini_API_key= userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "5bHX9-B4484j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "3rS_gprX5J9z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Create a Prompt Template"
      ],
      "metadata": {
        "id": "Q7b4k0hBxXQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_prompt = PromptTemplate(\n",
        "    input_variables = [\"Question\"],\n",
        "    template = \"Write a 5 key points {Question}\"\n",
        ")"
      ],
      "metadata": {
        "id": "CdpThm6tkqKt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm= GoogleGenerativeAI(\n",
        "    api_key= Gemini_API_key,\n",
        "    model= \"gemini-1.5-flash\"\n",
        ")"
      ],
      "metadata": {
        "id": "uQOWjQs6t1A2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Build the LangChain Pipeline (first Cahin)"
      ],
      "metadata": {
        "id": "7ipHcEhMxjh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_chain = first_prompt | llm"
      ],
      "metadata": {
        "id": "3cvd-Zb4mj1q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Run the Hello World Example\n",
        "\n",
        "Pass a sample question to the chain and print the response."
      ],
      "metadata": {
        "id": "mr7JvHQ8x2QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = first_chain.invoke({\"Question\": \"what is Lang chain\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7wb1bvK5g0T",
        "outputId": "9e762480-3a21-455d-8e5f-2e0ed943dcb6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain's core functionality can be summarized in these 5 key points:\n",
            "\n",
            "1. **Connects LLMs to other tools:** LangChain's primary function is to bridge Large Language Models (LLMs) with external data sources and APIs. This allows LLMs to access and process information beyond their training data, making them far more versatile and powerful.\n",
            "\n",
            "2. **Modular and extensible architecture:** It's built with a modular design, allowing developers to easily incorporate different LLMs, prompts, memory mechanisms, and other components.  This flexibility enables customization for various applications.\n",
            "\n",
            "3. **Manages chains of thought and actions:** LangChain excels at orchestrating sequences of operations (chains).  This could involve querying a database, processing the results with an LLM, then summarizing the output—all within a single, automated workflow.\n",
            "\n",
            "4. **Provides memory for LLMs:**  LLMs are stateless by nature. LangChain offers mechanisms to provide memory to LLMs, allowing them to retain context across multiple interactions within a conversation or task. This is crucial for maintaining coherence and relevance.\n",
            "\n",
            "5. **Simplifies LLM application development:**  LangChain significantly reduces the complexity of building LLM-powered applications. It provides pre-built components and tools, streamlining development and accelerating time to market.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9V7AX7Tg8rO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7sih0Hv28yJN"
      }
    }
  ]
}