{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwUy16+0xqK69aObKIsMoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mkhan512/B63_Q2_Projects/blob/LangChain_Projects/1st_LangChainProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project 1: LangChain Hello World Project\n",
        "            In this Project, we will create a simple LangChain Colab Notebook that uses the Google Gemini Flash 2.0 model to answer user questions. This example below is provided to help you get started assumes you have access to the Gemini API and a basic Python environment. However, you are required to develop and submit your project using Google Colab."
      ],
      "metadata": {
        "id": "kjDcrBbn81yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@ Step 1: Set Up the Environment"
      ],
      "metadata": {
        "id": "u3zPBCPiwb2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y build-essential libtool autoconf python3-dev"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xDRxvNzoqP7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://libarchive.googlecode.com/files/libarchive-3.0.3.tar.gz\n",
        "!tar xzf libarchive-3.0.3.tar.gz"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Yftjo6RfpKW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd libarchive-3.0.3\n",
        "!./build/autogen.sh\n",
        "!./configure --prefix=/usr/local\n",
        "!make\n",
        "!make install"
      ],
      "metadata": {
        "id": "2eVbrU-Oo0EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tT7FRAlVpt0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain.GOOGLE_genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HXGEk7KQpAmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "epXuin4Hwryh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gkmXEjAMxVh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install google-generative-ai"
      ],
      "metadata": {
        "id": "WQj3tTAzw66T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Configure the Gemini Flash Model"
      ],
      "metadata": {
        "id": "M9ZEUwwVwpry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "Gemini_API_key= userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "5bHX9-B4484j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "3rS_gprX5J9z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create a Prompt Template"
      ],
      "metadata": {
        "id": "Q7b4k0hBxXQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_prompt = PromptTemplate(\n",
        "    input_variables = [\"Question\"],\n",
        "    template = \"Write a 5 key points {Question}\"\n",
        ")"
      ],
      "metadata": {
        "id": "CdpThm6tkqKt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm= GoogleGenerativeAI(\n",
        "    api_key= Gemini_API_key,\n",
        "    model= \"gemini-1.5-flash\"\n",
        ")"
      ],
      "metadata": {
        "id": "uQOWjQs6t1A2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Build the LangChain Pipeline (first Cahin)"
      ],
      "metadata": {
        "id": "7ipHcEhMxjh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_chain = first_prompt | llm"
      ],
      "metadata": {
        "id": "3cvd-Zb4mj1q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5: Run the Hello World Example\n",
        "\n",
        "**Pass a sample question to the chain and print the response.**"
      ],
      "metadata": {
        "id": "mr7JvHQ8x2QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = first_chain.invoke({\"Question\": \"what is Lang chain\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7wb1bvK5g0T",
        "outputId": "9e762480-3a21-455d-8e5f-2e0ed943dcb6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain's core functionality can be summarized in these 5 key points:\n",
            "\n",
            "1. **Connects LLMs to other tools:** LangChain's primary function is to bridge Large Language Models (LLMs) with external data sources and APIs. This allows LLMs to access and process information beyond their training data, making them far more versatile and powerful.\n",
            "\n",
            "2. **Modular and extensible architecture:** It's built with a modular design, allowing developers to easily incorporate different LLMs, prompts, memory mechanisms, and other components.  This flexibility enables customization for various applications.\n",
            "\n",
            "3. **Manages chains of thought and actions:** LangChain excels at orchestrating sequences of operations (chains).  This could involve querying a database, processing the results with an LLM, then summarizing the outputâ€”all within a single, automated workflow.\n",
            "\n",
            "4. **Provides memory for LLMs:**  LLMs are stateless by nature. LangChain offers mechanisms to provide memory to LLMs, allowing them to retain context across multiple interactions within a conversation or task. This is crucial for maintaining coherence and relevance.\n",
            "\n",
            "5. **Simplifies LLM application development:**  LangChain significantly reduces the complexity of building LLM-powered applications. It provides pre-built components and tools, streamlining development and accelerating time to market.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9V7AX7Tg8rO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7sih0Hv28yJN"
      }
    }
  ]
}